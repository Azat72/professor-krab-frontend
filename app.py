import streamlit as st
import requests
import os
import re
import uuid
from PIL import Image

st.set_page_config(page_title="–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç", layout="wide")

API_URL = "https://professor-krab-backend.onrender.com"
SOURCE_DOCS_DIR = "source_docs"
LOGO_PATH = "logo_krab.png"

if "projects" not in st.session_state:
    st.session_state.projects = {}
if "project_names" not in st.session_state:
    st.session_state.project_names = {}
if "active_project" not in st.session_state:
    new_id = str(uuid.uuid4())
    st.session_state.projects[new_id] = []
    st.session_state.project_names[new_id] = "–ü—Ä–æ–µ–∫—Ç 1"
    st.session_state.active_project = new_id

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ª–æ–≥–æ—Ç–∏–ø
if os.path.exists(LOGO_PATH):
    st.image(LOGO_PATH, width=100)
st.markdown("## –ü—Ä–æ—Ñ–µ—Å—Å–æ—Ä –ö–†–ê–ë")

# –í—ã–±–æ—Ä –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤
st.sidebar.subheader("üìÅ –ú–æ–∏ –ø—Ä–æ–µ–∫—Ç—ã")
project_id_list = list(st.session_state.projects.keys())
current_project = st.sidebar.radio("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–µ–∫—Ç:", project_id_list, format_func=lambda x: st.session_state.project_names.get(x, x))
st.session_state.active_project = current_project

new_name = st.sidebar.text_input("‚úèÔ∏è –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –ø—Ä–æ–µ–∫—Ç:", value=st.session_state.project_names[current_project])
if st.sidebar.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–º—è"):
    st.session_state.project_names[current_project] = new_name
    st.rerun()

if st.sidebar.button("‚ûï –ù–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç"):
    new_id = str(uuid.uuid4())
    st.session_state.projects[new_id] = []
    st.session_state.project_names[new_id] = f"–ü—Ä–æ–µ–∫—Ç {len(st.session_state.projects)}"
    st.session_state.active_project = new_id
    st.rerun()

question = st.chat_input("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –±–∞–∑–µ:")

def find_matching_doc(source_name):
    def normalize(text):
        return re.sub(r"[^–∞-—èa-z0-9]", "", text.lower())
    target = normalize(source_name)
    for file in os.listdir(SOURCE_DOCS_DIR):
        if normalize(file).startswith(target):
            return os.path.join(SOURCE_DOCS_DIR, file)
    return None

# –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
for entry in st.session_state.projects[st.session_state.active_project]:
    with st.chat_message("user"):
        st.markdown(entry["question"])
    with st.chat_message("assistant"):
        st.markdown(entry["answer"])
        sources = entry.get("filtered_sources", [])
        if sources:
            st.markdown("**üìÑ –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –æ—Ç–≤–µ—Ç–æ–º:**")
            for doc in sources:
                doc_path = find_matching_doc(doc)
                if doc_path and os.path.exists(doc_path):
                    with open(doc_path, "rb") as f:
                        st.download_button(
                            label=f"üì• –°–∫–∞—á–∞—Ç—å {os.path.basename(doc_path)}",
                            data=f,
                            file_name=os.path.basename(doc_path),
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )
                else:
                    st.warning(f"‚ö† –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {doc}")

# –ó–∞–ø—Ä–æ—Å
if question:
    with st.chat_message("user"):
        st.markdown(question)
    try:
        history = [
            {"question": h["question"], "answer": h["answer"]}
            for h in st.session_state.projects[st.session_state.active_project]
        ]
        response = requests.post(API_URL, json={
            "question": question,
            "chat_history": history
        }, timeout=60)
        response.raise_for_status()
        result = response.json()

        debug_info = result.get("debug", [])
        filtered_sources = []
        seen_titles = set()
        for item in debug_info:
            score = item.get("score", 0)
            title = item.get("title")
            if title and score >= 0.58 and title not in seen_titles:
                filtered_sources.append(title)
                seen_titles.add(title)

        new_entry = {
            "question": question,
            "answer": result.get("answer", "–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞"),
            "sources": result.get("sources", []),
            "filtered_sources": filtered_sources
        }
        st.session_state.projects[st.session_state.active_project].append(new_entry)

        with st.chat_message("assistant"):
            st.markdown(new_entry["answer"])
            if filtered_sources:
                st.markdown("**üìÑ –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –æ—Ç–≤–µ—Ç–æ–º:**")
                for doc in filtered_sources:
                    doc_path = find_matching_doc(doc)
                    if doc_path and os.path.exists(doc_path):
                        with open(doc_path, "rb") as f:
                            st.download_button(
                                label=f"üì• –°–∫–∞—á–∞—Ç—å {os.path.basename(doc_path)}",
                                data=f,
                                file_name=os.path.basename(doc_path),
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )
                    else:
                        st.warning(f"‚ö† –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {doc}")

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ API: {e}")

st.markdown("---")
if st.button("üóë –û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–µ–∫—Ç"):
    st.session_state.projects[st.session_state.active_project] = []
    st.rerun()
